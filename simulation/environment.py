# simulation/environment.py
import asyncio
from datetime import datetime
from typing import List, Dict, Tuple

from skyfield.api import Topos

from config import MIN_MODELS_FOR_AGGREGATION, AGGREGATION_STALENESS_THRESHOLD, NUM_MASTERS, SATS_PER_PLANE
from ml.model import PyTorchModel, create_mobilenet
from ml.training import evaluate_model, fed_avg
from utils.logging_setup import KST
from utils.skyfield_utils import EarthSatellite
from simulation.satellite import Satellite, WorkerSatellite, MasterSatellite

class IoTCluster:
    """ë°ì´í„° ì†ŒìŠ¤ê°€ ë˜ëŠ” IoT í´ëŸ¬ìŠ¤í„°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, name: str, latitude: float, longitude: float, elevation: int, sim_logger=None):
        self.name = name
        self.topos = Topos(latitude_degrees=latitude, longitude_degrees=longitude, elevation_m=elevation)
        self.logger = sim_logger
        self.logger.info(f"IoT í´ëŸ¬ìŠ¤í„° '{self.name}' ìƒì„± ì™„ë£Œ.")

class GroundStation:
    """
    ì§€ìƒêµ­ í´ë˜ìŠ¤.
    - ìœ„ì„±ê³¼ì˜ í†µì‹ (AOS/LOS)ì„ ê´€ë¦¬
    - í´ëŸ¬ìŠ¤í„° ëª¨ë¸ì„ ìˆ˜ì‹ í•˜ê³  ê¸€ë¡œë²Œ ëª¨ë¸ì„ ì·¨í•©(Aggregation)
    - ì—…ë°ì´íŠ¸ëœ ê¸€ë¡œë²Œ ëª¨ë¸ì„ ìœ„ì„±ì— ì „íŒŒ
    """
    def __init__(self, name: str, latitude: float, longitude: float, elevation: int, initial_model: PyTorchModel, 
                 eval_infra: dict, threshold_deg: float = 10.0,
                 min_models_agg: int = MIN_MODELS_FOR_AGGREGATION, 
                 staleness_th: int = AGGREGATION_STALENESS_THRESHOLD):
        self.name = name
        self.topos = Topos(latitude_degrees=latitude, longitude_degrees=longitude, elevation_m=elevation)
        self.threshold_deg = threshold_deg
        self.global_model = initial_model
        self.received_models_buffer: List[PyTorchModel] = []
        self._comm_status: Dict[int, bool] = {}
        self.min_models_for_aggregation = min_models_agg
        self.staleness_threshold = staleness_th
        self.logger = eval_infra['sim_logger']
        self.perf_logger = eval_infra['perf_logger']
        self.test_loader = eval_infra['test_loader']
        self.device = eval_infra['device']
        self.logger.info(f"ì§€ìƒêµ­ '{self.name}' ìƒì„± ì™„ë£Œ. ê¸€ë¡œë²Œ ëª¨ë¸ ë²„ì „: {self.global_model.version}")
        self.logger.info(f"  - Aggregation ì •ì±…: ìµœì†Œ ëª¨ë¸ {self.min_models_for_aggregation}ê°œ, ë²„ì „ í—ˆìš©ì¹˜ {self.staleness_threshold}")

    async def run(self, clock: 'SimulationClock', satellites: Dict[int, 'Satellite']):
        self.logger.info(f"ì§€ìƒêµ­ '{self.name}' ìš´ì˜ ì‹œì‘.")
        asyncio.create_task(self.periodic_aggregation_task())
        while True:
            current_ts = clock.get_time_ts()
            for sat_id, sat in satellites.items():
                if not hasattr(sat, 'cluster_members'): continue # MasterSatelliteë§Œ ìƒëŒ€
                
                elevation = (sat.satellite_obj - self.topos).at(current_ts).altaz()[0].degrees
                prev_visible = self._comm_status.get(sat_id, False)
                visible_now = elevation >= self.threshold_deg

                if visible_now:
                    if not prev_visible: # First moment of contact (AOS)
                        self.logger.info(f"ğŸ“¡ [AOS] {self.name} <-> MasterSAT {sat_id} í†µì‹  ì‹œì‘ (ê³ ë„ê°: {elevation:.2f}Â°)")
                        sat.state = 'COMMUNICATING_GS'
                    
                    # 1. ìˆ˜ì‹  ë¨¼ì € ì‹œë„
                    if sat.model_ready_to_upload:
                        await self.receive_model_from_satellite(sat)
                        # ìˆ˜ì‹  ì§í›„ ë°”ë¡œ ì§‘ê³„ ì‹œë„í•˜ì—¬ ëª¨ë¸ ì¦‰ì‹œ ì—…ë°ì´íŠ¸
                        # await self.try_aggregate_and_update()
                    
                    # 2. ê·¸ ë‹¤ìŒ ì†¡ì‹ 
                    await self.send_model_to_satellite(sat)

                elif prev_visible and not visible_now: # LOS
                    self.logger.info(f"ğŸ“¡ [LOS] {self.name} <-> MasterSAT {sat_id} í†µì‹  ì¢…ë£Œ (ê³ ë„ê°: {elevation:.2f}Â°)")
                    sat.state = 'IDLE'
                
                self._comm_status[sat_id] = visible_now

            await asyncio.sleep(clock.real_interval)

    async def send_model_to_satellite(self, satellite: 'MasterSatellite'):
        if self.global_model.version > satellite.local_model.version:
            self.logger.info(f"  ğŸ“¤ {self.name} -> MasterSAT {satellite.sat_id}: ê¸€ë¡œë²Œ ëª¨ë¸ ì „ì†¡ (ë²„ì „ {self.global_model.version})")
            await satellite.receive_global_model(self.global_model)

    async def receive_model_from_satellite(self, satellite: 'MasterSatellite'):
        cluster_model = await satellite.send_local_model()
        if cluster_model:
            self.logger.info(f"  ğŸ“¥ {self.name} <- MasterSAT {satellite.sat_id}: í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ìˆ˜ì‹  ì™„ë£Œ (ë²„ì „ {cluster_model.version}, í•™ìŠµì: {cluster_model.trained_by})")
            self.received_models_buffer.append(cluster_model)

    async def periodic_aggregation_task(self):
        """ì£¼ê¸°ì ìœ¼ë¡œ Aggregationì„ ì‹œë„í•˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…"""
        while True:
            # self.logger.info(f"ğŸ•’ [{self.name}] Aggregation ì¡°ê±´ í™•ì¸ ì¤‘...")
            await self.try_aggregate_and_update()
            await asyncio.sleep(5) # 30ì´ˆ -> 5ì´ˆë¡œ ë‹¨ì¶•í•˜ì—¬ ë” ìì£¼ í™•ì¸
            
    async def try_aggregate_and_update(self):
        """Aggregation ì¡°ê±´ í™•ì¸ ë° ìˆ˜í–‰"""
        if len(self.received_models_buffer) < self.min_models_for_aggregation: return
        
        try:
            max_version_in_buffer = max(model.version for model in self.received_models_buffer)
        except ValueError:
            return # ë²„í¼ê°€ ë¹„ì—ˆì„ ê²½ìš°

        if max_version_in_buffer < self.global_model.version: return

        version_lower_bound = max_version_in_buffer - self.staleness_threshold
        models_to_aggregate = [m for m in self.received_models_buffer if m.version >= version_lower_bound]
        
        if len(models_to_aggregate) < self.min_models_for_aggregation: return

        self.logger.info(f"âœ¨ [{self.name} Aggregation] {len(models_to_aggregate)}ê°œ ëª¨ë¸(v >= {version_lower_bound})ê³¼ ê¸°ì¡´ ê¸€ë¡œë²Œ ëª¨ë¸(v{self.global_model.version}) ì·¨í•© ì‹œì‘...")
        
        state_dicts_to_avg = [self.global_model.model_state_dict] + [m.model_state_dict for m in models_to_aggregate]
        new_state_dict = fed_avg(state_dicts_to_avg)
        
        new_version = self.global_model.version + 1 # ë²„ì „ì—…
        all_contributors = list(set(self.global_model.trained_by + [p for model in models_to_aggregate for p in model.trained_by]))
        self.global_model = PyTorchModel(version=new_version, model_state_dict=new_state_dict, trained_by=all_contributors)
        self.logger.info(f"âœ¨ [{self.name} Aggregation] ìƒˆë¡œìš´ ê¸€ë¡œë²Œ ëª¨ë¸ ìƒì„± ì™„ë£Œ! (ë²„ì „ {self.global_model.version})")

        loop = asyncio.get_running_loop()
        accuracy, loss = await loop.run_in_executor(None, evaluate_model, self.global_model.model_state_dict, self.test_loader, self.device)
        self.logger.info(f"  ğŸ§ª [Global Test] Owner: {self.name}, Version: {self.global_model.version}, Accuracy: {accuracy:.2f}%, Loss: {loss:.4f}")
        self.perf_logger.info(f"{datetime.now(KST).isoformat()},GLOBAL_TEST,{self.name},{self.global_model.version},N/A,{accuracy:.4f},{loss:.6f}")

        aggregated_model_ids = {id(m) for m in models_to_aggregate}
        self.received_models_buffer = [m for m in self.received_models_buffer if id(m) not in aggregated_model_ids]
        
        if self.received_models_buffer:
            try:
                current_max_version = max(m.version for m in self.received_models_buffer)
                cleanup_lower_bound = current_max_version - self.staleness_threshold
                models_to_discard = [m for m in self.received_models_buffer if m.version < cleanup_lower_bound]
                if models_to_discard:
                    discard_versions = {m.version for m in models_to_discard}
                    self.logger.info(f"  ğŸ—‘ï¸  [{self.name}] {len(models_to_discard)}ê°œì˜ ì˜¤ë˜ëœ ëª¨ë¸ ì •ë¦¬ (ë²„ì „: {discard_versions})")
                    discard_model_ids = {id(m) for m in models_to_discard}
                    self.received_models_buffer = [m for m in self.received_models_buffer if id(m) not in discard_model_ids]
            except ValueError: pass

def create_simulation_environment(
    clock: 'SimulationClock', 
    eval_infra: dict, 
    all_sats_skyfield: Dict[int, EarthSatellite]
) -> Tuple[Dict[int, Satellite], List[GroundStation]]:
    """
    ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì„ êµ¬ì„±í•˜ëŠ” ëª¨ë“  ê°ì²´(ìœ„ì„±, ì§€ìƒêµ­, IoT)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    main.pyì—ì„œ TLE ë¡œë”© í›„, ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ í™˜ê²½ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
    """
    logger = eval_infra['sim_logger']
    
    # 1. ì´ˆê¸° ê¸€ë¡œë²Œ ëª¨ë¸ ìƒì„±
    initial_pytorch_model = create_mobilenet()
    initial_global_model = PyTorchModel(version=0, model_state_dict=initial_pytorch_model.state_dict())
    
    # 2. ì§€ìƒêµ­ ë° IoT í´ëŸ¬ìŠ¤í„° ìƒì„±
    ground_stations = [
        GroundStation("Seoul-GS", 37.5665, 126.9780, 34, initial_model=initial_global_model, eval_infra=eval_infra),
        # GroundStation("Houston-GS", 29.7604, -95.3698, 12, initial_model=initial_global_model, eval_infra=eval_infra)
    ]
    
    iot_clusters = [
        IoTCluster("Amazon_Forest", -3.47, -62.37, 100, sim_logger=logger),
        IoTCluster("Great_Barrier_Reef", -18.29, 147.77, 0, sim_logger=logger),
        IoTCluster("Siberian_Tundra", 68.35, 18.79, 420, sim_logger=logger)
    ]

    # 3. ìœ„ì„± ê°ì²´ ë° í´ëŸ¬ìŠ¤í„° êµ¬ì„± (ê¸°ì¡´ main.py ë¡œì§)
    satellites_in_sim: Dict[int, Satellite] = {}
    sat_ids = sorted(list(all_sats_skyfield.keys()))
    
    if len(sat_ids) < NUM_MASTERS * (SATS_PER_PLANE // NUM_MASTERS if NUM_MASTERS > 0 else SATS_PER_PLANE):
       raise ValueError(f"ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•´ ì¶©ë¶„í•œ ìˆ˜ì˜ ìœ„ì„± TLEê°€ í•„ìš”í•©ë‹ˆë‹¤.")
       
    master_ids = [sat_ids[i * SATS_PER_PLANE] for i in range(NUM_MASTERS)]
    worker_ids = [sid for sid in sat_ids if sid not in master_ids]
    
    logger.info(f"ë§ˆìŠ¤í„° ìœ„ì„±ìœ¼ë¡œ {master_ids}ê°€ ì„ ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

    masters = []
    for m_id in master_ids:
        master_sat = MasterSatellite(
            m_id, all_sats_skyfield[m_id], clock,
            initial_model=initial_global_model,
            iot_clusters=iot_clusters, eval_infra=eval_infra
        )
        satellites_in_sim[m_id] = master_sat
        masters.append(master_sat)

    for i, w_id in enumerate(worker_ids):
        assigned_master = masters[i % NUM_MASTERS]
        worker_sat = WorkerSatellite(
            w_id, all_sats_skyfield[w_id], clock,
            initial_model=initial_global_model,
            iot_clusters=iot_clusters,
            master=assigned_master, eval_infra=eval_infra
        )
        assigned_master.add_member(worker_sat)
        satellites_in_sim[w_id] = worker_sat
            
    logger.info(f"ì´ {len(satellites_in_sim)}ê°œ ìœ„ì„± ìƒì„± ì™„ë£Œ. ({len(masters)} Masters, {len(satellites_in_sim) - len(masters)} Workers)")
    
    return satellites_in_sim, ground_stations    